{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2\n",
    "## Named Entety Recognition and Event Extraction from Literary Fiction\n",
    "\n",
    "deadline: 12 декабря 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом LitBank. Корпус собран из популярных художественных произведений на английском языке и сожержит разметку по именованным сущностям и событиям. Объем корпуса таков: 100 текстов по примерно 2000 слов каждый. \n",
    "\n",
    "Корпус описан в статьях:\n",
    "* David Bamman, Sejal Popat, Sheng Shen, An Annotated Dataset of Literary Entities http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/naacl2019_literary_entities.pdf\n",
    "* Matthew Sims, Jong Ho Park, David Bamman, Literary Event Detection,  http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/acl2019_literary_events.pdf\n",
    "\n",
    "Корпус доступен в репозитории проекта:  https://github.com/dbamman/litbank\n",
    "\n",
    "Статья и код, использованный для извлечения именованных сущностей: \n",
    "* Meizhi Ju, Makoto Miwa and Sophia Ananiadou, A Neural Layered Model for Nested Named Entity Recognition, https://github.com/meizhiju/layered-bilstm-crf\n",
    "\n",
    "Структура корпуса устроена так. \n",
    "Первый уровень: \n",
    "* entities -- разметка по сущностям\n",
    "* events -- разметка по сущностям\n",
    "\n",
    "\n",
    "В корпусе используются 6 типов именованных сущностей: PER, LOC, ORG, FAC, GPE, VEH (имена, локации, организации, помещения, топонимы, средства перемещния), допускаются вложенные сущности. \n",
    "\n",
    "События выражается одним словом - *триггером*, которое может быть глагом, прилагательным и существительным. В корпусе описаны события, которые действительно происходят и не имеют гипотетического характера. \n",
    "Пример: she *walked* rapidly and resolutely, здесь *walked* -- триггер события. Типы событий не заданы. \n",
    "\n",
    "\n",
    "\n",
    "Второй уровень:\n",
    "* brat -- рабочие файлы инструмента разметки brat, ann-файлы содержат разметку, txt-файлы – сырые тексты \n",
    "* tsv -- tsv-файлы содержат разметку в IOB формате,\n",
    "\n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание сдается через github.classroom, инвайты будут высланы.\n",
    "3. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "4. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "5. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "6. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "7. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch.multiprocessing\n",
    "from typing import *\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset download and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data_dir = Path('data')\n",
    "top_data_dir.mkdir(exist_ok=True)\n",
    "data_dir = top_data_dir / 'litbank'\n",
    "\n",
    "if not data_dir.exists():\n",
    "    %cd data\n",
    "    !git clone https://github.com/dbamman/litbank\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import LitbankDataset\n",
    "\n",
    "dataset = LitbankDataset(data_dir)\n",
    "\n",
    "# Словари с датафреймом разметки для каждого текста\n",
    "entity_df_dict = dataset.df_dicts['entities']\n",
    "event_df_dict = dataset.df_dicts['events']\n",
    "# Объединенные датафреймы\n",
    "entity_df_all = dataset.dfs['entities']\n",
    "event_df_all = dataset.dfs['events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['541_the_age_of_innocence_brat.tsv', '2891_howards_end_brat.tsv', '2775_the_good_soldier_brat.tsv', '6593_history_of_tom_jones_a_foundling_brat.tsv', '44_the_song_of_the_lark_brat.tsv', '32_herland_brat.tsv', '271_black_beauty_brat.tsv', '4300_ulysses_brat.tsv', '351_of_human_bondage_brat.tsv', '940_the_last_of_the_mohicans_a_narrative_of_1757_brat.tsv', '238_dear_enemy_brat.tsv', '4217_a_portrait_of_the_artist_as_a_young_man_brat.tsv', '2084_the_way_of_all_flesh_brat.tsv', '233_sister_carrie_a_novel_brat.tsv', '974_the_secret_agent_a_simple_tale_brat.tsv', '1695_the_man_who_was_thursday_a_nightmare_brat.tsv', '5348_ragged_dick_or_street_life_in_new_york_with_the_bootblacks_brat.tsv', '514_little_women_brat.tsv', '730_oliver_twist_brat.tsv', '78_tarzan_of_the_apes_brat.tsv', '160_the_awakening_and_selected_short_stories_brat.tsv', '345_dracula_brat.tsv', '45_anne_of_green_gables_brat.tsv', '24_o_pioneers_brat.tsv', '2641_a_room_with_a_view_brat.tsv', '36_the_war_of_the_worlds_brat.tsv', '2095_clotelle_a_tale_of_the_southern_states_brat.tsv', '5230_the_invisible_man_a_grotesque_romance_brat.tsv', '434_the_circular_staircase_brat.tsv', '171_charlotte_temple_brat.tsv', '2852_the_hound_of_the_baskervilles_brat.tsv', '969_the_tenant_of_wildfell_hall_brat.tsv', '11_alices_adventures_in_wonderland_brat.tsv', '215_the_call_of_the_wild_brat.tsv', '1023_bleak_house_brat.tsv', '60_the_scarlet_pimpernel_brat.tsv', '367_country_of_the_pointed_firs_brat.tsv', '432_the_ambassadors_brat.tsv', '84_frankenstein_or_the_modern_prometheus_brat.tsv', '3268_the_mysteries_of_udolpho_brat.tsv', '145_middlemarch_brat.tsv', '11231_bartleby_the_scrivener_a_story_of_wallstreet_brat.tsv', '1342_pride_and_prejudice_brat.tsv', '3457_the_man_of_the_forest_brat.tsv', '76_adventures_of_huckleberry_finn_brat.tsv', '502_desert_gold_brat.tsv', '472_the_house_behind_the_cedars_brat.tsv', '768_wuthering_heights_brat.tsv', '41286_miss_marjoribanks_brat.tsv', '18581_adrift_in_new_york_tom_and_florence_braving_the_world_brat.tsv', '33_the_scarlet_letter_brat.tsv', '209_the_turn_of_the_screw_brat.tsv', '805_this_side_of_paradise_brat.tsv', '2807_to_have_and_to_hold_brat.tsv', '110_tess_of_the_durbervilles_a_pure_woman_brat.tsv', '1064_the_masque_of_the_red_death_brat.tsv', '4051_lady_bridget_in_the_nevernever_land_a_story_of_australian_life_brat.tsv', '27_far_from_the_madding_crowd_brat.tsv', '829_gullivers_travels_into_several_remote_nations_of_the_world_brat.tsv', '41_the_legend_of_sleepy_hollow_brat.tsv', '6053_evelina_or_the_history_of_a_young_ladys_entrance_into_the_world_brat.tsv', '77_the_house_of_the_seven_gables_brat.tsv', '95_the_prisoner_of_zenda_brat.tsv', '766_david_copperfield_brat.tsv', '2814_dubliners_brat.tsv', '73_the_red_badge_of_courage_an_episode_of_the_american_civil_war_brat.tsv', '876_life_in_the_ironmills_or_the_korl_woman_brat.tsv', '74_the_adventures_of_tom_sawyer_brat.tsv', '2489_moby_dick_brat.tsv', '16357_mary_a_fiction_brat.tsv', '219_heart_of_darkness_brat.tsv', '113_the_secret_garden_brat.tsv', '521_the_life_and_adventures_of_robinson_crusoe_brat.tsv', '2005_piccadilly_jim_brat.tsv', '8867_the_magnificent_ambersons_brat.tsv', '543_main_street_brat.tsv', '711_allan_quatermain_brat.tsv', '550_silas_marner_brat.tsv', '599_vanity_fair_brat.tsv', '217_sons_and_lovers_brat.tsv', '1155_the_secret_adversary_brat.tsv', '208_daisy_miller_a_study_brat.tsv', '1260_jane_eyre_an_autobiography_brat.tsv', '932_the_fall_of_the_house_of_usher_brat.tsv', '12677_personality_plus_some_experiences_of_emma_mcchesney_and_her_son_jock_brat.tsv', '9830_the_beautiful_and_damned_brat.tsv', '62_a_princess_of_mars_brat.tsv', '1327_elizabeth_and_her_german_garden_brat.tsv', '1400_great_expectations_brat.tsv', '1661_the_adventures_of_sherlock_holmes_brat.tsv', '155_the_moonstone_brat.tsv', '2166_king_solomons_mines_brat.tsv', '1206_the_flying_u_ranch_brat.tsv', '15265_the_quest_of_the_silver_fleece_a_novel_brat.tsv', '120_treasure_island_brat.tsv', '4276_north_and_south_brat.tsv', '174_the_picture_of_dorian_gray_brat.tsv', '105_persuasion_brat.tsv', '1245_night_and_day_brat.tsv', '158_emma_brat.tsv'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label0</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Book</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>shocking</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>walk</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>”</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>“</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210532 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token label0 label1 label2 label3 label4\n",
       "0         Book      O      O      O      O      0\n",
       "1            I      O      O      O      O      0\n",
       "2           I.      O      O      O      O      0\n",
       "3           On      O      O      O      O      0\n",
       "4            a      O      O      O      O      0\n",
       "...        ...    ...    ...    ...    ...    ...\n",
       "2058  shocking      O      O      O      O      0\n",
       "2059      walk      O      O      O      O      0\n",
       "2060         .      O      O      O      O      0\n",
       "2061         ”      O      O      O      O      0\n",
       "2062         “      O      O      O      O      0\n",
       "\n",
       "[210532 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Часть 1. [3 балла] Эксплоративный анализ\n",
    "1. Найдите топ 10 (по частоте) именованных сущностей каждого из 6 типов.\n",
    "2. Найдите топ 10 (по частоте) частотных триггеров событий.\n",
    "3. Кластеризуйте все уникальные триггеры событий, используя эмбеддинги слов и любой алгоритм кластеризации (например, агломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий?\n",
    "\n",
    "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу и сравните кластеры тригеров и выделенные темы: есть ли схожие паттерны в тематической модели и в стурктуре кластеров?\n",
    "\n",
    "В следующих частях домашнего задания вам понадобится train-test-dev разбиение. Авторы статей предлагают следующую структуру разбиения: обучающее множество – 80 книг, валидационное – 10 книг, тестовое – 10 книг. Предложения из одного источника не должны попадать в разные сегменты разбиения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Найдите топ 10 (по частоте) именованных сущностей каждого из 6 типов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пройдем по каждой строке датафрейма с разметкой и будем сохранять, сколько раз каждое слово являлось той или иной сущностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 по встречаемости cущностей\n",
      "\n",
      "PER\n",
      "[('the', 2148), ('a', 1137), ('of', 776), (',', 670), ('his', 406), ('man', 361), ('who', 309), ('Mr.', 307), ('and', 305), ('her', 289)]\n",
      "\n",
      "FAC\n",
      "[('the', 1194), ('a', 260), ('of', 223), ('house', 153), (',', 138), ('room', 100), ('home', 83), ('The', 80), ('and', 76), ('in', 74)]\n",
      "\n",
      "GPE\n",
      "[('the', 172), ('town', 64), ('of', 55), ('London', 40), ('a', 39), ('England', 38), ('country', 34), ('New', 27), ('village', 27), (',', 26)]\n",
      "\n",
      "VEH\n",
      "[('the', 97), ('a', 33), ('ship', 21), ('car', 15), ('train', 14), ('ships', 12), ('The', 11), ('carriage', 10), ('_', 10), ('boats', 8)]\n",
      "\n",
      "LOC\n",
      "[('the', 828), ('of', 195), ('a', 122), ('world', 112), (',', 64), ('sea', 56), ('and', 53), ('river', 50), ('country', 47), ('this', 42)]\n",
      "\n",
      "ORG\n",
      "[('the', 86), ('of', 28), ('a', 21), ('army', 20), (',', 19), ('and', 10), ('that', 7), ('his', 7), ('Church', 7), ('an', 6)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "entity_words_dict = defaultdict(Counter)\n",
    "\n",
    "for i, (token, *labels) in entity_df_all.iterrows():\n",
    "    for label in labels:\n",
    "        if label in [0, '0', 'O']:\n",
    "            continue\n",
    "        # Игнорируем X в X-NER\n",
    "        label = label.split('-')[-1]\n",
    "        entity_words_dict[label][token] += 1\n",
    "\n",
    "print('Топ-10 по встречаемости cущностей\\n')\n",
    "for label, counter in entity_words_dict.items():\n",
    "    print(label)\n",
    "    print(counter.most_common(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Найдите топ 10 (по частоте) частотных триггеров событий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое, но еще проще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 по встречаемости событий\n",
      "\n",
      "[('said', 464), ('came', 95), ('looked', 92), ('went', 92), ('asked', 69), ('heard', 63), ('saw', 59), ('cried', 59), ('took', 56), ('turned', 55)]\n"
     ]
    }
   ],
   "source": [
    "event_words_counter = Counter()\n",
    "\n",
    "for i, (token, label) in event_df_all.iterrows():\n",
    "    if label == 'EVENT':\n",
    "        event_words_counter[token] += 1\n",
    "\n",
    "print('Топ-10 по встречаемости событий\\n')\n",
    "\n",
    "print(event_words_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Кластеризуйте все уникальные триггеры событий, используя эмбеддинги слов и любой алгоритм кластеризации (например, агломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import gensim.downloader\n",
    "\n",
    "\n",
    "word2vec_model = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "words = list(event_words_counter.keys())\n",
    "X = np.array([word2vec_model.get_vector(word) for word in words\n",
    "              if word in word2vec_model.key_to_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AgglomerativeClustering(distance_threshold=30, n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AgglomerativeClustering</label><div class=\"sk-toggleable__content\"><pre>AgglomerativeClustering(distance_threshold=30, n_clusters=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AgglomerativeClustering(distance_threshold=30, n_clusters=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model = AgglomerativeClustering(distance_threshold=30, n_clusters=None)\n",
    "cluster_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ слов по встречаемости из кластера 0\n",
      "[('came', 95), ('looked', 92), ('went', 92), ('asked', 69), ('saw', 59), ('turned', 55), ('come', 37), ('returned', 34), ('see', 34), ('replied', 30)]\n",
      "Топ слов по встречаемости из кластера 1\n",
      "[('told', 51), ('fire', 34), ('met', 26), ('reached', 26), ('felt', 25), ('spoke', 25), ('called', 24), ('stopped', 22), ('saying', 18), ('fell', 18)]\n",
      "Топ слов по встречаемости из кластера 2\n",
      "[('took', 56), ('answered', 45), ('put', 44), ('walked', 30), ('brought', 27), ('seen', 21), ('remember', 20), ('died', 19), ('sent', 18), ('death', 17)]\n",
      "Топ слов по встречаемости из кластера 3\n",
      "[('found', 49), ('thought', 38), ('looking', 30), ('glance', 23), ('observed', 22), ('pulled', 17), ('says', 16), ('watched', 13), ('explained', 12), ('promised', 11)]\n",
      "Топ слов по встречаемости из кластера 4\n",
      "[('said', 464), ('heard', 63), ('got', 34), ('made', 31), ('tried', 25), ('shook', 18), ('set', 17), ('walking', 14), ('struck', 13), ('fog', 13)]\n",
      "Топ слов по встречаемости из кластера 5\n",
      "[('cried', 59), ('wind', 19), ('gave', 16), ('tears', 15), ('cry', 14), ('go', 9), ('interrupted', 9), ('moved', 8), ('drank', 7), ('accepted', 7)]\n",
      "Топ слов по встречаемости из кластера 6\n",
      "[('left', 36), ('raised', 8), ('leaving', 7), ('smelling', 4), ('rushed', 4), ('caught', 4), ('buried', 4), ('presented', 4), ('hunted', 3), ('plunged', 3)]\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(cluster_model.n_clusters_):\n",
    "\n",
    "    non_cluster_words = [words[i] for i, label in enumerate(cluster_model.labels_)\n",
    "                         if label != cluster]\n",
    "    cluster_words_counter = event_words_counter.copy()\n",
    "    for word in non_cluster_words:\n",
    "        cluster_words_counter.pop(word)\n",
    "\n",
    "    print(f'Топ слов по встречаемости из кластера {cluster}')\n",
    "    most_common = cluster_words_counter.most_common(10)\n",
    "    print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-ой кластер: глаголы движения\n",
    "\n",
    "1-ый кластер: много слов связанных с разговорами\n",
    "\n",
    "2-ый кластер: много слов связанных с манипуляцией предметами (положить/взять)\n",
    "\n",
    "3-ый кластер: слова связанные с наблюдением\n",
    "\n",
    "5-ый кластер: слова связанные с грустью\n",
    "\n",
    "6-ый кластер: слова связанные с дикой живностью (охота, выращивать, поймать)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. [5 баллов] Извлечение именованных сущностей\n",
    "1. Используйте стандартную (любую предобученную) модель для извлечения именованных сущностей. Продемонстрируйте, какие сущности она извлекает. Вычислите качество работы модели на токенах и на спанах сущностей. Для вычисления качества работы модели используйте seqeval (умеет работать с Huggingface). Какая из метрик получилась выше?\n",
    "\n",
    "2. Дообучите BERT для извлечения именованных сущностей.\n",
    "\n",
    "2. (Как вариант альтернативный обучению BERT) Можно обучить модель CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей.\n",
    "Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация)\n",
    "\n",
    "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018] Можно использовать модель из статьи, можно также вместо эмбеддингов слов использовать ELMo и/или BERT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Использование предобученной модели spacy для извлечения сущностей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset litbank (/Users/germanarutunov/.cache/huggingface/datasets/litbank/entities/1.0.0/d59773a054f99e4ef93e0f4f5a5389a84b457c6cb12f9203595bc30a02f9711c)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6d8a69df3d64e2cbf73dafc237bb165"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import dataset.litbank\n",
    "import inspect\n",
    "\n",
    "dataset = load_dataset(inspect.getfile(dataset.litbank), 'entities')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы использовать датасет напрямую, выложим его в HF Hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "#\n",
    "# login()\n",
    "#\n",
    "# dataset.push_to_hub('garutyunov/litbank-entities')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/germanarutunov/.cache/huggingface/datasets/litbank/entities/1.0.0/d59773a054f99e4ef93e0f4f5a5389a84b457c6cb12f9203595bc30a02f9711c/cache-840c560c967b1131.arrow and /Users/germanarutunov/.cache/huggingface/datasets/litbank/entities/1.0.0/d59773a054f99e4ef93e0f4f5a5389a84b457c6cb12f9203595bc30a02f9711c/cache-a05ed42e2d68f31c.arrow\n"
     ]
    }
   ],
   "source": [
    "split = dataset['train'].train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of true tokens and pred tokens are not equal for 62: 2031 != 2032\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.training.iob_utils import biluo_to_iob, doc_to_biluo_tags\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "preds = []\n",
    "\n",
    "for hf_doc in split['test']:\n",
    "    doc = Doc(\n",
    "        vocab=nlp.vocab,\n",
    "        words=hf_doc['tokens'],\n",
    "    )\n",
    "    pred = nlp(str(doc))\n",
    "    tags = doc_to_biluo_tags(pred)\n",
    "\n",
    "    iob = hf_doc['ner_tags']\n",
    "    iob_pred = biluo_to_iob(tags)\n",
    "\n",
    "    if len(iob) != len(iob_pred):\n",
    "        print(f'Lengths of true tokens and pred tokens are not equal for {hf_doc[\"id\"]}: {len(iob)} != {len(iob_pred)}')\n",
    "        continue\n",
    "\n",
    "    y_true.append(iob)\n",
    "    y_pred.append(iob_pred)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/germanarutunov/Library/Caches/pypoetry/virtualenvs/hw-2-nlp-hse-2022-andboys-J7wYp4hM-py3.9/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/germanarutunov/Library/Caches/pypoetry/virtualenvs/hw-2-nlp-hse-2022-andboys-J7wYp4hM-py3.9/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00         0\n",
      "         FAC       0.24      0.01      0.02       345\n",
      "         GPE       0.43      0.29      0.34        94\n",
      "    LANGUAGE       0.00      0.00      0.00         0\n",
      "         LAW       0.00      0.00      0.00         0\n",
      "         LOC       0.26      0.02      0.04       208\n",
      "       MONEY       0.00      0.00      0.00         0\n",
      "        NORP       0.00      0.00      0.00         0\n",
      "     ORDINAL       0.00      0.00      0.00         0\n",
      "         ORG       0.07      0.27      0.11        15\n",
      "         PER       0.00      0.00      0.00      1658\n",
      "      PERSON       0.00      0.00      0.00         0\n",
      "     PRODUCT       0.00      0.00      0.00         0\n",
      "    QUANTITY       0.00      0.00      0.00         0\n",
      "        TIME       0.00      0.00      0.00         0\n",
      "         VEH       0.00      0.00      0.00        44\n",
      " WORK_OF_ART       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.04      0.02      0.02      2364\n",
      "   macro avg       0.06      0.03      0.03      2364\n",
      "weighted avg       0.07      0.02      0.02      2364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наибольшее значение у метрики weighted avg precision (0.07), в целом значения все очень низкие, так как модель плохо предсказала сущности, а особенности PER."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from spacy.displacy import render\n",
    "\n",
    "render(preds, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Дообучим BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from lightning_transformers.task.nlp.token_classification import (\n",
    "    TokenClassificationDataModule,\n",
    "    TokenClassificationTransformer,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"bert-base-uncased\")\n",
    "dm = TokenClassificationDataModule(\n",
    "    batch_size=4,\n",
    "    task_name=\"ner\",\n",
    "    dataset_name=\"garutyunov/litbank-entities\",\n",
    "    preprocessing_num_workers=torch.multiprocessing.cpu_count(),\n",
    "    label_all_tokens=False,\n",
    "    revision=\"main\",\n",
    "    tokenizer=tokenizer,\n",
    "    train_val_split=0.2,\n",
    "    seed=42,\n",
    ")\n",
    "model = TokenClassificationTransformer(pretrained_model_name_or_path=\"bert-base-uncased\", labels=dm.num_classes)\n",
    "trainer = pl.Trainer(accelerator=\"auto\", strategy=\"ddp_fork\", devices=\"auto\", max_epochs=10, log_every_n_steps=10)\n",
    "\n",
    "trainer.fit(model, dm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучение производилось отдельно в Google Colab, так что у ячейки сверху нет вывода. Ячейка снизу показывает то, как была выложена модель в HF Hub."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from transformers import AutoModel\n",
    "#\n",
    "# model.save_hf_checkpoints('checkpoints')\n",
    "#\n",
    "# hf_model = AutoModel.from_pretrained('checkpoints')\n",
    "# hf_model.push_to_hub('garutyunov/litbert')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее используем обученную и выложенную в HF Hub модель."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ячейка для запуска Google Colab\n",
    "# !pip install Pillow=9.0.0\n",
    "# !pip install git+https://github.com/gaarutyunov/lightning-transformers.git\n",
    "#\n",
    "# import pytorch_lightning as pl\n",
    "# from transformers import AutoTokenizer\n",
    "#\n",
    "# from lightning_transformers.task.nlp.token_classification import (\n",
    "#     TokenClassificationDataModule,\n",
    "#     TokenClassificationTransformer,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"bert-base-uncased\")\n",
    "dm = TokenClassificationDataModule(\n",
    "    batch_size=4,\n",
    "    task_name=\"ner\",\n",
    "    dataset_name=\"garutyunov/litbank-entities\",\n",
    "    label_all_tokens=False,\n",
    "    revision=\"main\",\n",
    "    tokenizer=tokenizer,\n",
    "    train_val_split=0.2,\n",
    "    seed=42,\n",
    ")\n",
    "model = TokenClassificationTransformer(pretrained_model_name_or_path=\"garutyunov/litbert\", labels=dm.num_classes, tokenizer=tokenizer)\n",
    "model.trainer = pl.Trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.hf_predict(split[\"test\"]['text'][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. [2 балла] Извлечение событий\n",
    "\n",
    "1. Используйте BiLSTM на эмбеддингах слов для извлечения триггеров событий.\n",
    "\n",
    "2. Замените часть модели на  словах  на ELMo и/или BERT.  Должна получиться модель ELMo / BERT + BiLSTM.\n",
    "\n",
    "[бонус] Предобучите BiLSTM как языковую модель. Дообучите ее для извлечения триггеров.\n",
    "\n",
    "[бонус] Дообучите BERT для извлечения триггеров событий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Часть 4. [2 балла] Одновременное извлечение именованных сущностей и событий\n",
    "1. Обучите модель для совместного извлечения именованных сущностей и триггеров событий. У модели должен быть общий энкодер (например, BERT, CNN + BiLSMT, ELMo + BiLSTM, BERT + BiLSTM) и два декодера: один отвечает за извлечение именнованных сущностей, другой отвечает за извлечение триггеров событий.\n",
    "\n",
    "[бонус] Добавьте в модель механизм внимания, так, как это покажется вам разумным.\n",
    "\n",
    "[бонус] Визуализируйте карты механизма внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Часть 5. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
