{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2\n",
    "## Named Entety Recognition and Event Extraction from Literary Fiction\n",
    "\n",
    "deadline: 12 декабря 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом LitBank. Корпус собран из популярных художественных произведений на английском языке и сожержит разметку по именованным сущностям и событиям. Объем корпуса таков: 100 текстов по примерно 2000 слов каждый. \n",
    "\n",
    "Корпус описан в статьях:\n",
    "* David Bamman, Sejal Popat, Sheng Shen, An Annotated Dataset of Literary Entities http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/naacl2019_literary_entities.pdf\n",
    "* Matthew Sims, Jong Ho Park, David Bamman, Literary Event Detection,  http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/acl2019_literary_events.pdf\n",
    "\n",
    "Корпус доступен в репозитории проекта:  https://github.com/dbamman/litbank\n",
    "\n",
    "Статья и код, использованный для извлечения именованных сущностей: \n",
    "* Meizhi Ju, Makoto Miwa and Sophia Ananiadou, A Neural Layered Model for Nested Named Entity Recognition, https://github.com/meizhiju/layered-bilstm-crf\n",
    "\n",
    "Структура корпуса устроена так. \n",
    "Первый уровень: \n",
    "* entities -- разметка по сущностям\n",
    "* events -- разметка по сущностям\n",
    "\n",
    "\n",
    "В корпусе используются 6 типов именованных сущностей: PER, LOC, ORG, FAC, GPE, VEH (имена, локации, организации, помещения, топонимы, средства перемещния), допускаются вложенные сущности. \n",
    "\n",
    "События выражается одним словом - *триггером*, которое может быть глагом, прилагательным и существительным. В корпусе описаны события, которые действительно происходят и не имеют гипотетического характера. \n",
    "Пример: she *walked* rapidly and resolutely, здесь *walked* -- триггер события. Типы событий не заданы. \n",
    "\n",
    "\n",
    "\n",
    "Второй уровень:\n",
    "* brat -- рабочие файлы инструмента разметки brat, ann-файлы содержат разметку, txt-файлы – сырые тексты \n",
    "* tsv -- tsv-файлы содержат разметку в IOB формате,\n",
    "\n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание сдается через github.classroom, инвайты будут высланы.\n",
    "3. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "4. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "5. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "6. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "7. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset download and init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = Path('data/litbank')\n",
    "\n",
    "if not data_dir.exists():\n",
    "    %cd data\n",
    "    !git clone https://github.com/dbamman/litbank\n",
    "    %cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils import LitbankDataset\n",
    "\n",
    "dataset = LitbankDataset(data_dir)\n",
    "\n",
    "# Словари с датафреймом разметки для каждого текста\n",
    "entity_df_dict = dataset.df_dicts['entities']\n",
    "event_df_dict = dataset.df_dicts['events']\n",
    "# Объединенные датафреймы\n",
    "entity_df_all = dataset.dfs['entities']\n",
    "event_df_all = dataset.dfs['events']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['541_the_age_of_innocence_brat.tsv', '2891_howards_end_brat.tsv', '2775_the_good_soldier_brat.tsv', '6593_history_of_tom_jones_a_foundling_brat.tsv', '44_the_song_of_the_lark_brat.tsv', '32_herland_brat.tsv', '271_black_beauty_brat.tsv', '4300_ulysses_brat.tsv', '351_of_human_bondage_brat.tsv', '940_the_last_of_the_mohicans_a_narrative_of_1757_brat.tsv', '238_dear_enemy_brat.tsv', '4217_a_portrait_of_the_artist_as_a_young_man_brat.tsv', '2084_the_way_of_all_flesh_brat.tsv', '233_sister_carrie_a_novel_brat.tsv', '974_the_secret_agent_a_simple_tale_brat.tsv', '1695_the_man_who_was_thursday_a_nightmare_brat.tsv', '5348_ragged_dick_or_street_life_in_new_york_with_the_bootblacks_brat.tsv', '514_little_women_brat.tsv', '730_oliver_twist_brat.tsv', '78_tarzan_of_the_apes_brat.tsv', '160_the_awakening_and_selected_short_stories_brat.tsv', '345_dracula_brat.tsv', '45_anne_of_green_gables_brat.tsv', '24_o_pioneers_brat.tsv', '2641_a_room_with_a_view_brat.tsv', '36_the_war_of_the_worlds_brat.tsv', '2095_clotelle_a_tale_of_the_southern_states_brat.tsv', '5230_the_invisible_man_a_grotesque_romance_brat.tsv', '434_the_circular_staircase_brat.tsv', '171_charlotte_temple_brat.tsv', '2852_the_hound_of_the_baskervilles_brat.tsv', '969_the_tenant_of_wildfell_hall_brat.tsv', '11_alices_adventures_in_wonderland_brat.tsv', '215_the_call_of_the_wild_brat.tsv', '1023_bleak_house_brat.tsv', '60_the_scarlet_pimpernel_brat.tsv', '367_country_of_the_pointed_firs_brat.tsv', '432_the_ambassadors_brat.tsv', '84_frankenstein_or_the_modern_prometheus_brat.tsv', '3268_the_mysteries_of_udolpho_brat.tsv', '145_middlemarch_brat.tsv', '11231_bartleby_the_scrivener_a_story_of_wallstreet_brat.tsv', '1342_pride_and_prejudice_brat.tsv', '3457_the_man_of_the_forest_brat.tsv', '76_adventures_of_huckleberry_finn_brat.tsv', '502_desert_gold_brat.tsv', '472_the_house_behind_the_cedars_brat.tsv', '768_wuthering_heights_brat.tsv', '41286_miss_marjoribanks_brat.tsv', '18581_adrift_in_new_york_tom_and_florence_braving_the_world_brat.tsv', '33_the_scarlet_letter_brat.tsv', '209_the_turn_of_the_screw_brat.tsv', '805_this_side_of_paradise_brat.tsv', '2807_to_have_and_to_hold_brat.tsv', '110_tess_of_the_durbervilles_a_pure_woman_brat.tsv', '1064_the_masque_of_the_red_death_brat.tsv', '4051_lady_bridget_in_the_nevernever_land_a_story_of_australian_life_brat.tsv', '27_far_from_the_madding_crowd_brat.tsv', '829_gullivers_travels_into_several_remote_nations_of_the_world_brat.tsv', '41_the_legend_of_sleepy_hollow_brat.tsv', '6053_evelina_or_the_history_of_a_young_ladys_entrance_into_the_world_brat.tsv', '77_the_house_of_the_seven_gables_brat.tsv', '95_the_prisoner_of_zenda_brat.tsv', '766_david_copperfield_brat.tsv', '2814_dubliners_brat.tsv', '73_the_red_badge_of_courage_an_episode_of_the_american_civil_war_brat.tsv', '876_life_in_the_ironmills_or_the_korl_woman_brat.tsv', '74_the_adventures_of_tom_sawyer_brat.tsv', '2489_moby_dick_brat.tsv', '16357_mary_a_fiction_brat.tsv', '219_heart_of_darkness_brat.tsv', '113_the_secret_garden_brat.tsv', '521_the_life_and_adventures_of_robinson_crusoe_brat.tsv', '2005_piccadilly_jim_brat.tsv', '8867_the_magnificent_ambersons_brat.tsv', '543_main_street_brat.tsv', '711_allan_quatermain_brat.tsv', '550_silas_marner_brat.tsv', '599_vanity_fair_brat.tsv', '217_sons_and_lovers_brat.tsv', '1155_the_secret_adversary_brat.tsv', '208_daisy_miller_a_study_brat.tsv', '1260_jane_eyre_an_autobiography_brat.tsv', '932_the_fall_of_the_house_of_usher_brat.tsv', '12677_personality_plus_some_experiences_of_emma_mcchesney_and_her_son_jock_brat.tsv', '9830_the_beautiful_and_damned_brat.tsv', '62_a_princess_of_mars_brat.tsv', '1327_elizabeth_and_her_german_garden_brat.tsv', '1400_great_expectations_brat.tsv', '1661_the_adventures_of_sherlock_holmes_brat.tsv', '155_the_moonstone_brat.tsv', '2166_king_solomons_mines_brat.tsv', '1206_the_flying_u_ranch_brat.tsv', '15265_the_quest_of_the_silver_fleece_a_novel_brat.tsv', '120_treasure_island_brat.tsv', '4276_north_and_south_brat.tsv', '174_the_picture_of_dorian_gray_brat.tsv', '105_persuasion_brat.tsv', '1245_night_and_day_brat.tsv', '158_emma_brat.tsv'])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df_dict.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "         token label0 label1 label2 label3 label4\n0         Book      O      O      O      O      0\n1            I      O      O      O      O      0\n2           I.      O      O      O      O      0\n3           On      O      O      O      O      0\n4            a      O      O      O      O      0\n...        ...    ...    ...    ...    ...    ...\n2058  shocking      O      O      O      O      0\n2059      walk      O      O      O      O      0\n2060         .      O      O      O      O      0\n2061         ”      O      O      O      O      0\n2062         “      O      O      O      O      0\n\n[210532 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>label0</th>\n      <th>label1</th>\n      <th>label2</th>\n      <th>label3</th>\n      <th>label4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Book</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I.</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>On</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2058</th>\n      <td>shocking</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2059</th>\n      <td>walk</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2060</th>\n      <td>.</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2061</th>\n      <td>”</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2062</th>\n      <td>“</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>210532 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df_all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Часть 1. [3 балла] Эксплоративный анализ\n",
    "1. Найдите топ 10 (по частоте) именованных сущностей каждого из 6 типов.\n",
    "2. Найдите топ 10 (по частоте) частотных триггеров событий.\n",
    "3. Кластеризуйте все уникальные триггеры событий, используя эмбеддинги слов и любой алгоритм кластеризации (например, агломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий?\n",
    "\n",
    "[бонус] Визуализируйте полученные кластеры с помощью TSNE или UMAP\n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу и сравните кластеры тригеров и выделенные темы: есть ли схожие паттерны в тематической модели и в стурктуре кластеров?\n",
    "\n",
    "В следующих частях домашнего задания вам понадобится train-test-dev разбиение. Авторы статей предлагают следующую структуру разбиения: обучающее множество – 80 книг, валидационное – 10 книг, тестовое – 10 книг. Предложения из одного источника не должны попадать в разные сегменты разбиения.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Найдите топ 10 (по частоте) именованных сущностей каждого из 6 типов."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пройдем по каждой строке датафрейма с разметкой и будем сохранять, сколько раз каждое слово являлось той или иной сущностью"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 по встречаемости cущностей\n",
      "\n",
      "PER\n",
      "[('the', 2148), ('a', 1137), ('of', 776), (',', 670), ('his', 406), ('man', 361), ('who', 309), ('Mr.', 307), ('and', 305), ('her', 289)]\n",
      "\n",
      "FAC\n",
      "[('the', 1194), ('a', 260), ('of', 223), ('house', 153), (',', 138), ('room', 100), ('home', 83), ('The', 80), ('and', 76), ('in', 74)]\n",
      "\n",
      "GPE\n",
      "[('the', 172), ('town', 64), ('of', 55), ('London', 40), ('a', 39), ('England', 38), ('country', 34), ('New', 27), ('village', 27), (',', 26)]\n",
      "\n",
      "VEH\n",
      "[('the', 97), ('a', 33), ('ship', 21), ('car', 15), ('train', 14), ('ships', 12), ('The', 11), ('carriage', 10), ('_', 10), ('boats', 8)]\n",
      "\n",
      "LOC\n",
      "[('the', 828), ('of', 195), ('a', 122), ('world', 112), (',', 64), ('sea', 56), ('and', 53), ('river', 50), ('country', 47), ('this', 42)]\n",
      "\n",
      "ORG\n",
      "[('the', 86), ('of', 28), ('a', 21), ('army', 20), (',', 19), ('and', 10), ('that', 7), ('his', 7), ('Church', 7), ('an', 6)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "entity_words_dict = defaultdict(Counter)\n",
    "\n",
    "for i, (token, *labels) in entity_df_all.iterrows():\n",
    "    for label in labels:\n",
    "        if label in [0, '0', 'O']:\n",
    "            continue\n",
    "        # Игнорируем X в X-NER\n",
    "        label = label.split('-')[-1]\n",
    "        entity_words_dict[label][token] += 1\n",
    "\n",
    "print('Топ-10 по встречаемости cущностей\\n')\n",
    "for label, counter in entity_words_dict.items():\n",
    "    print(label)\n",
    "    print(counter.most_common(10))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Найдите топ 10 (по частоте) частотных триггеров событий."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "То же самое, но еще проще"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 по встречаемости событий\n",
      "\n",
      "[('said', 464), ('came', 95), ('looked', 92), ('went', 92), ('asked', 69), ('heard', 63), ('saw', 59), ('cried', 59), ('took', 56), ('turned', 55)]\n"
     ]
    }
   ],
   "source": [
    "event_words_counter = Counter()\n",
    "\n",
    "for i, (token, label) in event_df_all.iterrows():\n",
    "    if label == 'EVENT':\n",
    "        event_words_counter[token] += 1\n",
    "\n",
    "print('Топ-10 по встречаемости событий\\n')\n",
    "\n",
    "print(event_words_counter.most_common(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Кластеризуйте все уникальные триггеры событий, используя эмбеддинги слов и любой алгоритм кластеризации (например, агломеративный иерархический алгоритм кластеризации) и попробуйте проинтерпретировать кластеры: есть ли очевидные типы событий?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import gensim.downloader\n",
    "\n",
    "\n",
    "word2vec_model = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "words = list(event_words_counter.keys())\n",
    "X = np.array([word2vec_model.get_vector(word) for word in words\n",
    "              if word in word2vec_model.key_to_index])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "AgglomerativeClustering(distance_threshold=30, n_clusters=None)",
      "text/html": "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AgglomerativeClustering(distance_threshold=30, n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AgglomerativeClustering</label><div class=\"sk-toggleable__content\"><pre>AgglomerativeClustering(distance_threshold=30, n_clusters=None)</pre></div></div></div></div></div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model = AgglomerativeClustering(distance_threshold=30, n_clusters=None)\n",
    "cluster_model.fit(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ слов по встречаемости из кластера 0\n",
      "[('came', 95), ('looked', 92), ('went', 92), ('asked', 69), ('saw', 59), ('turned', 55), ('come', 37), ('returned', 34), ('see', 34), ('replied', 30)]\n",
      "Топ слов по встречаемости из кластера 1\n",
      "[('told', 51), ('fire', 34), ('met', 26), ('reached', 26), ('felt', 25), ('spoke', 25), ('called', 24), ('stopped', 22), ('saying', 18), ('fell', 18)]\n",
      "Топ слов по встречаемости из кластера 2\n",
      "[('took', 56), ('answered', 45), ('put', 44), ('walked', 30), ('brought', 27), ('seen', 21), ('remember', 20), ('died', 19), ('sent', 18), ('death', 17)]\n",
      "Топ слов по встречаемости из кластера 3\n",
      "[('found', 49), ('thought', 38), ('looking', 30), ('glance', 23), ('observed', 22), ('pulled', 17), ('says', 16), ('watched', 13), ('explained', 12), ('promised', 11)]\n",
      "Топ слов по встречаемости из кластера 4\n",
      "[('said', 464), ('heard', 63), ('got', 34), ('made', 31), ('tried', 25), ('shook', 18), ('set', 17), ('walking', 14), ('struck', 13), ('fog', 13)]\n",
      "Топ слов по встречаемости из кластера 5\n",
      "[('cried', 59), ('wind', 19), ('gave', 16), ('tears', 15), ('cry', 14), ('go', 9), ('interrupted', 9), ('moved', 8), ('drank', 7), ('accepted', 7)]\n",
      "Топ слов по встречаемости из кластера 6\n",
      "[('left', 36), ('raised', 8), ('leaving', 7), ('smelling', 4), ('rushed', 4), ('caught', 4), ('buried', 4), ('presented', 4), ('hunted', 3), ('plunged', 3)]\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(cluster_model.n_clusters_):\n",
    "\n",
    "    non_cluster_words = [words[i] for i, label in enumerate(cluster_model.labels_)\n",
    "                         if label != cluster]\n",
    "    cluster_words_counter = event_words_counter.copy()\n",
    "    for word in non_cluster_words:\n",
    "        cluster_words_counter.pop(word)\n",
    "\n",
    "    print(f'Топ слов по встречаемости из кластера {cluster}')\n",
    "    most_common = cluster_words_counter.most_common(10)\n",
    "    print(most_common)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0-ой кластер: глаголы движения\n",
    "\n",
    "1-ый кластер: много слов связанных с разговорами\n",
    "\n",
    "2-ый кластер: много слов связанных с манипуляцией предметами (положить/взять)\n",
    "\n",
    "3-ый кластер: слова связанные с наблюдением\n",
    "\n",
    "5-ый кластер: слова связанные с грустью\n",
    "\n",
    "6-ый кластер: слова связанные с дикой живностью (охота, выращивать, поймать)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 2. [5 баллов] Извлечение именованных сущностей\n",
    "1. Используйте стандартную (любую предобученную) модель для извлечения именованных сущностей. Продемонстрируйте, какие сущности она извлекает. Вычислите качество работы модели на токенах и на спанах сущностей. Для вычисления качества работы модели используйте seqeval (умеет работать с Huggingface). Какая из метрик получилась выше?\n",
    "\n",
    "2. Дообучите BERT для извлечения именованных сущностей.\n",
    "\n",
    "2. (Как вариант альтернативный обучению BERT) Можно обучить модель CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей.\n",
    "Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация)\n",
    "\n",
    "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018] Можно использовать модель из статьи, можно также вместо эмбеддингов слов использовать ELMo и/или BERT.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Часть 3. [2 балла] Извлечение событий\n",
    "\n",
    "1. Используйте BiLSTM на эмбеддингах слов для извлечения триггеров событий.\n",
    "\n",
    "2. Замените часть модели на  словах  на ELMo и/или BERT.  Должна получиться модель ELMo / BERT + BiLSTM.\n",
    "\n",
    "[бонус] Предобучите BiLSTM как языковую модель. Дообучите ее для извлечения триггеров.\n",
    "\n",
    "[бонус] Дообучите BERT для извлечения триггеров событий."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Часть 4. [2 балла] Одновременное извлечение именованных сущностей и событий\n",
    "1. Обучите модель для совместного извлечения именованных сущностей и триггеров событий. У модели должен быть общий энкодер (например, BERT, CNN + BiLSMT, ELMo + BiLSTM, BERT + BiLSTM) и два декодера: один отвечает за извлечение именнованных сущностей, другой отвечает за извлечение триггеров событий.\n",
    "\n",
    "[бонус] Добавьте в модель механизм внимания, так, как это покажется вам разумным.\n",
    "\n",
    "[бонус] Визуализируйте карты механизма внимания."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Часть 5. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
